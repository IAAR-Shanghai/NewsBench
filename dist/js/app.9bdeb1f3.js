(function(){"use strict";var t={8572:function(t,e,a){var n=a(5130),i=a(6768);const s={id:"app"},r=(0,i.Lk)("br",null,null,-1);function o(t,e,a,n,o,l){const d=(0,i.g2)("router-view");return(0,i.uX)(),(0,i.CE)("div",s,[r,(0,i.bF)(d)])}var l={name:"App"},d=a(1241);const c=(0,d.A)(l,[["render",o]]);var u=c,h=a(973);const p=(0,i.Lk)("br",null,null,-1),g={class:"title-container"},f={class:"text-center title",style:{"font-size":"larger"}},m=["src"],b=(0,i.Fv)('<div class="container"><p class="author text-center"><a href="#" style="white-space:nowrap;">Miao Li</a><sup>1</sup> and <a href="#" style="white-space:nowrap;">Ming-Bin Chen</a><sup>1</sup> and <a href="#" style="white-space:nowrap;">Bo Tang</a><sup>2</sup> and <a href="#" style="white-space:nowrap;">Shengbin Hou</a><sup>3</sup> and <a href="#" style="white-space:nowrap;">Pengyu Wang</a><sup>3</sup> and <a href="#" style="white-space:nowrap;">Haiying Deng</a><sup>4</sup> and <a href="#" style="white-space:nowrap;">Zhiyu Li</a><sup>2</sup> and <a href="#" style="white-space:nowrap;">Feiyu Xiong</a><sup>2</sup> and <a href="#" style="white-space:nowrap;">Keming Mao</a><sup>3</sup> and <a href="#" style="white-space:nowrap;">Peng Cheng</a><sup>4</sup> and <a href="#" style="white-space:nowrap;">Yi Luo</a><sup>4</sup></p></div><div class="container"><p class="author text-center"><a style="white-space:nowrap;font-size:small;"><sup>1</sup>The University of Melbourne, Australia</a>    <a style="white-space:nowrap;font-size:small;"><sup>2</sup>IAAR, China</a>    <a style="white-space:nowrap;font-size:small;"><sup>3</sup>Northeastern University, China</a>    <a style="white-space:nowrap;font-size:small;"><sup>4</sup>State Key Laboratory of Media Convergence Production Technology and Systems, China</a>       </p><p class="author text-center" style="font-size:small;color:grey;"> miao4@student.unimelb.edu.au, tangb@iaar.ac.cn </p></div><div class="container text-center"><button type="button" class="btn btn-dark"><a href="#" style="color:white;">Code</a></button>    <button type="button" class="btn btn-dark"><a href="https://arxiv.org/abs/2403.00862" style="color:white;">Paper</a></button></div><br><br><div class="container text-center"><h2 class="title" style="text-align:center;">Abstract</h2><p class="paragraph">This study presents NewsBench, a novel benchmak framework developed to evaluate the capabiity of Large Lanquage Models (lMs)in Chinese jouralisticWriting Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with Al utilization. Comprising1.267 tasks across 5 editoral applications, 7 aspects (incuding safety and iouralisic wrting with 4 detaled facets), and spanning 24 news topics domains,NewsBench emplys wo GPT-4 based automalic evalualion proiocols validated by buman assessment Our comprehensive anawsis of 41 ulMs highightedGPT-4 and ERNlE Bot as top performers, yet revealed a relative deficiency in joumalisic ethic adherence duing creative wrting tasks. These findings underscorthe need for enhanced ethical quidance in Al-generated joumalisic content, marking a step fonward in aigning Al capablies with jouralistic standards andsafety considerations.</p></div><br><div class="jumbotron jumbotron-fluid text-center" style="background-color:aliceblue;"><div class="container"><h5 class="display-4">Overview</h5></div></div><br><div class="p-container"><p class="paragraph">The widespread adoption of Large Language Models (LLMs) such as OpenAI&#39;s ChatGPT has prompted discussions on the responsible use of this technology due to its non-deterministic nature. While efforts have been made to address safety concerns, there is a lack of standardized benchmarks for evaluating LLMs&#39; alignment with journalistic ethics. To bridge this gap, this paper introduces NewsBench, a comprehensive benchmark evaluation framework for assessing LLMs in journalistic writing and safety compliance. Through automatic evaluation protocols and comparative analysis of 11 LLMs, including GPT-4 and ERNIE Bot, this study identifies their strengths and weaknesses in adhering to journalistic standards. Our key contributions are:</p><p class="paragraph" style="width:90%;margin:0 auto;">• Developed NewsBench, a benchmark for evaluating LLMs on journalistic writing and safety, featuring generative and multiplechoice tasks across 5 applications and 7 aspects.</p><br><p class="paragraph" style="width:90%;margin:0 auto;">• Introduced two GPT-4-based evaluation protocols for journalistic writing proficiency and safety compliance, validated by human annotation</p><br><p class="paragraph" style="width:90%;margin:0 auto;">• Conducted a comparative analysis and error assessment of 11 LLMs, identifying strengths and weaknesses.</p><br><p class="paragraph" style="width:90%;margin:0 auto;">• Identified GPT-4 and ERNIE Bot as leading models, highlighting their limitations in adhering to journalistic ethics in creative writing tasks.</p></div><br><br><div class="jumbotron jumbotron-fluid text-center" style="background-color:aliceblue;"><div class="container"><h5 class="display-4">Framework</h5></div></div><br>',14),y={class:"p-container"},v=(0,i.Lk)("p",{class:"paragraph"},"The benchmark evaluates two principal criteria: Journalistic Writing Proficiency (JWP) and Safety Adherence (SA) in content generated by LLMs. Our framework includes both open-ended generation tasks and multiple-choice tasks, with 4 subsets totaling 1267 tasks: JWP generation tasks, JWP multiple choice tasks, SA generation tasks, and SA multiple choice tasks. Each subset covers 5 common journalistic editorial applications and up to 24 domains.",-1),w=(0,i.Lk)("p",{class:"paragraph"},"Figure 1 illustrates the comprehensive design of the NewsBench evaluation framework. Tasks from four subsets are inputted into a targeted LLM to elicit corresponding multiple-choice answers and generated textual responses. Two specialized automatic evaluation protocols based on GPT-4 assess the LLM's Journalistic Writing Proficiency and Safety Adherence.",-1),k=["src"],L=(0,i.Lk)("figcaption",{class:"figure-caption"},"Figure 1: The key components and processes of the NewsBench benchmark. The numbers inside the brackets indicate the task counts for the subsets. The bold border boxes are the output scores",-1),B=(0,i.Lk)("br",null,null,-1),x=(0,i.Lk)("br",null,null,-1),T=(0,i.Lk)("div",{class:"jumbotron jumbotron-fluid text-center",style:{"background-color":"aliceblue"}},[(0,i.Lk)("div",{class:"container"},[(0,i.Lk)("h5",{class:"display-4"},"Evalutation Protocol")])],-1),M=(0,i.Lk)("br",null,null,-1),P={class:"p-container"},j=(0,i.Lk)("p",{class:"paragraph"},"Our evaluation framework automates the assessment of large language models in journalistic writing proficiency and safety adherence, utilizing two automatic evaluation protocols based on recent advancements in natural language generation evaluation methodologies. We comprehensively evaluate journalistic writing proficiency, considering language fluency, logical coherence, style alignment, and instruction fulfillment, while providing tailored evaluation prompts for each safety aspect to ensure validity and reliability.Table 1 shows the evaluation prompts for the 6 SA aspects.",-1),C=["src"],A=(0,i.Lk)("figcaption",{class:"figure-caption"},"Table 1: Evaluation prompts for the 6 SA aspects",-1),E=(0,i.Lk)("p",{class:"paragraph"},null,-1),S=(0,i.Lk)("p",{class:"paragraph"},null,-1),O=(0,i.Lk)("p",{class:"paragraph"},null,-1),W=(0,i.Lk)("br",null,null,-1),G=(0,i.Lk)("br",null,null,-1),N=(0,i.Lk)("div",{class:"jumbotron jumbotron-fluid text-center",style:{"background-color":"aliceblue"}},[(0,i.Lk)("div",{class:"container"},[(0,i.Lk)("h5",{class:"display-4"},"Main Results")])],-1),z=(0,i.Lk)("br",null,null,-1),I={class:"p-container"},F=(0,i.Lk)("p",{class:"paragraph"},"We evaluated 11 LLMs capable of generating Chinese text, including GPT-4-1106, GPT-3.5-turbo, ERNIE Bot, Baichuan2-13B, Baichuan2-53B, ChatGLM2-6B, ChatGLM3-6B, Aquila-34B, InternLM-20B, Qwen-14B, Xinyu2-70B, and Xverse. These models cover corpora ranging from 2.6 trillion to 3.2 trillion tokens. Our evaluation spanned 1,267 benchmark samples.",-1),X=["src"],J=(0,i.Lk)("figcaption",{class:"figure-caption"},"Table 2: Evaluated large language models capable of generating Chinese.",-1),R=(0,i.Lk)("p",{class:"paragraph"},"In Table 2,in tasks related to journalistic writing proficiency, GPT-4-1106 emerged as the top performer, while ERNIE Bot showcased notable performance in safety evaluation and multiple-choice questions. Further analysis revealed that model size is not the sole determinant of performance; model architecture and training methodologies are equally crucial. ERNIE Bot demonstrated outstanding performance in addressing bias and discrimination, particularly excelling in summarization tasks. These findings shed light on the nuanced strengths of different models in the realm of journalistic writing proficiency.",-1),_=(0,i.Fv)('<br><br><div class="jumbotron jumbotron-fluid text-center" style="background-color:aliceblue;"><div class="container"><h5 class="display-4">Limitations</h5></div></div><br><div class="p-container" style="display:flex;"><div style="width:50%;"><h4 style="text-align:left;">Limitations</h4><p style="font-size:small;">There are several limitations to this study. Firstly, our dataset is exclusively in Chinese, limiting the applicability of the evaluation framework to other languages. Secondly, while our benchmark dataset is substantial, plans for expansion are in place to enhance comprehensiveness. The uneven distribution of samples across contexts is noted as well. Thirdly, the framework relies solely on the implicit knowledge embedded within LLMs for evaluation, which may result in inaccuracies when external evidence is required.</p></div><div style="width:10%;"><p></p></div><div style="width:50%;"><h4 style="text-align:left;">Constraints</h4><p style="font-size:small;">The dataset is limited to Chinese, potentially limiting its applicability to other languages. Uneven sample distribution and sole reliance on LLMs&#39; embedded knowledge, lacking external evidence, may lead to inaccuracies. The exclusion of certain essential editorial applications reflects a limitation in comprehensively assessing journalistic integrity within the framework. Besides,please note that this content contains examples of impolite or sensitive language related to news safety issues. Sensitive individuals may wish to disregard.</p></div></div><br><br><div class="p-container"><h3 style="text-align:left;">BibTeX</h3><pre style="background-color:lightgrey;"><code style="font-size:x-small;">\n  @misc{li2024newsbench,\n        title={NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications}, \n        author={Miao Li and Ming-Bin Chen and Bo Tang and Shengbin Hou and Pengyu Wang and Haiying Deng and Zhiyu Li and Feiyu Xiong and Keming Mao and Peng Cheng and Yi Luo},\n        year={2024},\n        eprint={2403.00862},\n        archivePrefix={arXiv},\n        primaryClass={cs.CL}\n  }\n      </code></pre></div>',8);function q(t,e,a,n,s,r){return(0,i.uX)(),(0,i.CE)("div",null,[p,(0,i.Lk)("div",g,[(0,i.Lk)("p",f,[(0,i.Lk)("img",{src:s.paper,width:"70",height:"70",class:"d-inline-block align-center",alt:""},null,8,m),(0,i.eW)(" News Benchmark: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications ")])]),b,(0,i.Lk)("div",y,[v,w,(0,i.Lk)("img",{src:s.newsbench_architecture,style:{width:"50%",height:"50%"},class:"rounded mx-auto d-block",alt:"..."},null,8,k),L]),B,x,T,M,(0,i.Lk)("div",P,[j,(0,i.Lk)("img",{src:s.prompt,style:{width:"70%",height:"70%"},class:"rounded mx-auto d-block",alt:"..."},null,8,C),A,E,S,O]),W,G,N,z,(0,i.Lk)("div",I,[F,(0,i.Lk)("img",{src:s.score,style:{width:"80%",height:"80%"},class:"rounded mx-auto d-block",alt:"..."},null,8,X),J,R]),_])}var H={name:"MyHome",data(){return{paper:a(3172),newsbench_architecture:a(7264),prompt:a(3822),score:a(7760)}}};const D=(0,d.A)(H,[["render",q]]);var K=D;const U=(0,i.Lk)("br",null,null,-1),Q={class:"text-center"},Y=["src"],Z=(0,i.Fv)('<br><div class="table-container"><table class="table table-hover table-borderless"><thead class="thead-light"><tr class="table-dark"><th scope="col">#</th><th scope="col">Model</th><th scope="col">#Parameters</th><th scope="col">Open Weights</th><th scope="col">JWP-Generation</th><th scope="col">JWP-Multiple</th><th scope="col">SA-Generation</th><th scope="col">SA-Multiple</th></tr></thead><tbody><tr><th scope="row">1</th><td>GPT-4-1106</td><td>-</td><td>×</td><td>2.4438</td><td>0.4560</td><td>0.9000</td><td>0.9068</td></tr><tr><th scope="row">2</th><td>GPT-3.5-turbo</td><td>-</td><td>×</td><td>2.3758</td><td>0.3070</td><td>0.7892</td><td>0.6281</td></tr><tr><th scope="row">3</th><td>ERNIE Bot</td><td>-</td><td>×</td><td>2.4112</td><td>0.5264</td><td>0.8456</td><td>0.8867</td></tr><tr><th scope="row">4</th><td>Baichuan2-13B</td><td>13B</td><td>√</td><td>2.3392</td><td>0.3452</td><td>0.7211</td><td>0.5842</td></tr><tr><th scope="row">5</th><td>Baichuan2-53B</td><td>53B</td><td>√</td><td>2.4088</td><td>0.3456</td><td>0.7883</td><td>0.6628</td></tr><tr><th scope="row">6</th><td>ChatGLM2-6B</td><td>6B</td><td>√</td><td>2.2658</td><td>0.3103</td><td>0.7534</td><td>0.5228</td></tr><tr><th scope="row">7</th><td>ChatGLM3-6B</td><td>6B</td><td>√</td><td>2.3082</td><td>0.3303</td><td>0.7599</td><td>0.4883</td></tr><tr><th scope="row">8</th><td>Aquila-34B</td><td>34B</td><td>√</td><td>2.1808</td><td>0.2401</td><td>0.7885</td><td>0.2687</td></tr><tr><th scope="row">9</th><td>InternLM-20B</td><td>20B</td><td>√</td><td>2.2208</td><td>0.4008</td><td>0.7669</td><td>0.5813</td></tr><tr><th scope="row">10</th><td>Qwen-14B</td><td>14B</td><td>√</td><td>2.3796</td><td>0.4408</td><td>0.7053</td><td>0.7324</td></tr><tr><th scope="row">11</th><td>Xinyu2-70B</td><td>70B</td><td>×</td><td>2.2916</td><td>0.3958</td><td>0.7393</td><td>0.5972</td></tr><tr><th scope="row">12</th><td>Xverse</td><td>13B</td><td>√</td><td>2.3968</td><td>0.3861</td><td>0.7702</td><td>0.5948</td></tr></tbody></table></div>',2);function V(t,e,a,n,s,r){return(0,i.uX)(),(0,i.CE)("div",null,[U,(0,i.Lk)("h3",Q,[(0,i.Lk)("img",{src:s.paper,width:"60",height:"60",class:"d-inline-block align-center",alt:""},null,8,Y),(0,i.eW)(" NewsBench Leaderboard ")]),Z])}var $={name:"MyLeaderboard",data(){return{paper:a(3172)}}};const tt=(0,d.A)($,[["render",V]]);var et=tt;const at=[{path:"/",component:K},{path:"/leaderboard",component:et}],nt=(0,h.aE)({history:(0,h.Bt)("/news_benchmark/"),routes:at});var it=nt;(0,n.Ef)(u).use(it).mount("#app")},7264:function(t,e,a){t.exports=a.p+"img/newsbench_architecture1.fa82da5a.png"},3172:function(t,e,a){t.exports=a.p+"img/paper.48e16696.png"},3822:function(t,e,a){t.exports=a.p+"img/prompt.fc049f4e.png"},7760:function(t,e,a){t.exports=a.p+"img/score.2673a4b0.png"}},e={};function a(n){var i=e[n];if(void 0!==i)return i.exports;var s=e[n]={exports:{}};return t[n].call(s.exports,s,s.exports,a),s.exports}a.m=t,function(){var t=[];a.O=function(e,n,i,s){if(!n){var r=1/0;for(c=0;c<t.length;c++){n=t[c][0],i=t[c][1],s=t[c][2];for(var o=!0,l=0;l<n.length;l++)(!1&s||r>=s)&&Object.keys(a.O).every((function(t){return a.O[t](n[l])}))?n.splice(l--,1):(o=!1,s<r&&(r=s));if(o){t.splice(c--,1);var d=i();void 0!==d&&(e=d)}}return e}s=s||0;for(var c=t.length;c>0&&t[c-1][2]>s;c--)t[c]=t[c-1];t[c]=[n,i,s]}}(),function(){a.n=function(t){var e=t&&t.__esModule?function(){return t["default"]}:function(){return t};return a.d(e,{a:e}),e}}(),function(){a.d=function(t,e){for(var n in e)a.o(e,n)&&!a.o(t,n)&&Object.defineProperty(t,n,{enumerable:!0,get:e[n]})}}(),function(){a.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(t){if("object"===typeof window)return window}}()}(),function(){a.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)}}(),function(){a.p="/news_benchmark/"}(),function(){var t={524:0};a.O.j=function(e){return 0===t[e]};var e=function(e,n){var i,s,r=n[0],o=n[1],l=n[2],d=0;if(r.some((function(e){return 0!==t[e]}))){for(i in o)a.o(o,i)&&(a.m[i]=o[i]);if(l)var c=l(a)}for(e&&e(n);d<r.length;d++)s=r[d],a.o(t,s)&&t[s]&&t[s][0](),t[s]=0;return a.O(c)},n=self["webpackChunknews_benchmark"]=self["webpackChunknews_benchmark"]||[];n.forEach(e.bind(null,0)),n.push=e.bind(null,n.push.bind(n))}();var n=a.O(void 0,[504],(function(){return a(8572)}));n=a.O(n)})();
//# sourceMappingURL=app.9bdeb1f3.js.map